{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e2c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbc813bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir jsonl_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperscraper.pubmed import get_and_dump_pubmed_papers\n",
    "\n",
    "from paperscraper.pdf import save_pdf_from_dump\n",
    "\n",
    "def cache_paper(query, top_k=10, jsonl_cache_dir = 'jsonl_cache'):\n",
    "    get_and_dump_pubmed_papers(query, output_filepath=jsonl_cache_dir + f'/{'_'.join(query)}.jsonl', max_results=top_k)\n",
    "    save_pdf_from_dump(jsonl_cache_dir + f'/{'_'.join(query)}.jsonl', pdf_path='doi_cache/', key_to_save='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperscraper.pdf import save_pdf_from_dump\n",
    "\n",
    "from paperscraper.pdf import save_pdf_from_dump\n",
    "\n",
    "# Save PDFs/XMLs in current folder and name the files by their DOI\n",
    "save_pdf_from_dump('covid19_ai_imaging.jsonl', pdf_path='doi_cache', key_to_save='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c0577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf4llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "file = pymupdf.open(\"doi_cache/10.3389_fdgth.2025.1551298.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36bb3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, -1, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# Extract the table of contents (TOC) in a structured form\n",
    "\n",
    "def extract_toc(file, level = 2):\n",
    "\n",
    "    toc = file.get_toc()\n",
    "\n",
    "    # Convert the TOC into a structured dictionary\n",
    "    structured_toc = [{'level': item[0], 'title': item[1], 'page': item[2]} for item in toc if item[0] == level]\n",
    "\n",
    "    # Display the structured TOC\n",
    "    structured_toc\n",
    "    # Extract text for each part and store it in the same structure as structured_toc\n",
    "    for i, section in enumerate(structured_toc):\n",
    "        start_page = section['page'] - 1  # pymupdf uses 0-based indexing for pages\n",
    "        end_page = structured_toc[i + 1]['page'] - 1 if i + 1 < len(structured_toc) else len(file)  # Determine the end page\n",
    "        \n",
    "        # Extract text from all pages in the range\n",
    "        section_text = \"\"\n",
    "        for page_number in range(start_page, end_page):\n",
    "            section_text += file[page_number].get_text()\n",
    "        section['start_page'] = start_page\n",
    "        section['end_page'] = end_page\n",
    "        section['page_count'] = end_page - start_page+1\n",
    "        \n",
    "        section['text'] = section_text\n",
    "        \n",
    "    return structured_toc\n",
    "\n",
    "    \n",
    "def union_pages(start_page_1, end_page_1, start_page_2, end_page_2):\n",
    "    \"\"\"\n",
    "    Check if two page ranges overlap and return the union of the ranges.\n",
    "    \"\"\"\n",
    "    if start_page_1 > end_page_1 or start_page_2 > end_page_2:\n",
    "        return None\n",
    "    if end_page_1 < start_page_2 or end_page_2 < start_page_1:\n",
    "        return list(range(start_page_1, end_page_1 + 1))+ [-1,] + list(range(start_page_2, end_page_2 + 1))\n",
    "    else:\n",
    "        # Overlapping ranges\n",
    "        if start_page_1 < start_page_2:\n",
    "            return list(range(start_page_1, end_page_2 + 1))\n",
    "        else:\n",
    "            return list(range(start_page_2, end_page_1 + 1))\n",
    "        \n",
    "        \n",
    "\n",
    "print(union_pages(1,3, 5,7))\n",
    "# Display the updated structured TOC with text\n",
    "# structured_toc\n",
    "def collect_all_section_texts_to_read(selected_section_names ,sections):\n",
    "    text = \"\"\n",
    "    for section in sections:\n",
    "        \n",
    "        # print(section['title'])\n",
    "        if section['title'] not in selected_section_names:\n",
    "            print(f\"Skipping {section['title']} as it is not in the selected sections.\")\n",
    "            continue\n",
    "            \n",
    "        text += f\"{str(section)}: \\n\" + section['text'] + \"\\n\\n\"\n",
    "        \n",
    "    return text\n",
    "\n",
    "def truncate_pages_to_read(file,  start=5, end=3):\n",
    "    \"\"\"\n",
    "    Truncate the pages to read to a specified number of pages.\n",
    "    \"\"\"\n",
    "    page_numbers = file.page_count\n",
    "    end_index = page_numbers - end\n",
    "    if end_index < start:\n",
    "        end_index = start\n",
    "    truncated_text = \"\"\n",
    "    for page_number in range(start, end_index):\n",
    "        truncated_text += file[page_number].get_text()\n",
    "    return truncated_text\n",
    "\n",
    "\n",
    "# truncate_pages_to_read(file, 5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff043b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  \n",
    "client = anthropic.Client()#api_key=\"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\")\n",
    "\n",
    "def call_claude(system_prompt, user_prompt):\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            \n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_prompt,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "\n",
    "call_llm = call_claude\n",
    "\n",
    "system_prompt = \"You are a scientific assistant. You are reading a scientific paper and extracting information based on the user's query. You should focus on the method section primarily, but also consider other sections if necessary. Your task is to provide a concise and accurate response to the user's query.\"\n",
    "\n",
    "def read_paper(query, preference_text='read the method section primarily', \n",
    "               ):\n",
    "    \"\"\"\n",
    "    Read the paper and extract information based on the query.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The query to search for in the paper.\n",
    "        preference_text (str): The preference text to guide the reading.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted information from the paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Construct the user prompt\n",
    "    user_prompt = f\"Read the following paper and {preference_text}.\\n\\n\"\n",
    "    user_prompt += f\"Paper Title: {paper_title}\\n\\n\"\n",
    "    user_prompt += f\"Paper Abstract: {paper_abstract}\\n\\n\"\n",
    "    user_prompt += f\"Paper Text: {paper_text}\\n\\n\"\n",
    "    user_prompt += f\"Query: {query}\\n\\n\"\n",
    "    \n",
    "    # Call Claude with the constructed prompt\n",
    "    response = call_llm(system_prompt, user_prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "028fea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main finding of the paper?\"\n",
    "# paper_title = \"A Novel Approach to COVID-19 Diagnosis Using AI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f07595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_reading(file, call_llm):\n",
    "    toc = extract_toc(file, level = 2)\n",
    "\n",
    "    if len(toc)>0:\n",
    "        # let LLM read the ToC and decide which sections to read\n",
    "        sections = [toc[i]['title'] for i in range(len(toc))]\n",
    "        \n",
    "        llm_selection_prompt = f\"Read the following table of contents and select the sections that are most relevant to the query: {query}.\\n\\n\"\n",
    "        llm_selection_prompt += f\"Table of Contents: {sections}\\n\\n\"\n",
    "        llm_selection_prompt += f\"Respond with the selected sections only, comma separated after Selected:\\n\\n\"\n",
    "        llm_selection = call_llm(system_prompt, llm_selection_prompt)\n",
    "        print(llm_selection)\n",
    "        \n",
    "        # parse the selection\n",
    "        \n",
    "        for line in llm_selection.split('\\n'):\n",
    "            if line.startswith('Selected:'):\n",
    "                llm_selection = line.split(':')[1].strip().split(',')\n",
    "                break\n",
    "        text_to_read = collect_all_section_texts_to_read(llm_selection, toc)\n",
    "        # parse the selection \n",
    "    else:\n",
    "        text_to_read = truncate_pages_to_read(file, 5, 3)\n",
    "    return text_to_read  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f148a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "Selected: Introduction, Experiments, Discussion, Conclusion\n",
      "Skipping Related work as it is not in the selected sections.\n",
      "Skipping Method as it is not in the selected sections.\n",
      "Skipping Experiments as it is not in the selected sections.\n",
      "Skipping Discussion as it is not in the selected sections.\n",
      "Skipping Conclusion as it is not in the selected sections.\n",
      "Skipping Data availability statement as it is not in the selected sections.\n",
      "Skipping Author contributions as it is not in the selected sections.\n",
      "Skipping Funding as it is not in the selected sections.\n",
      "Skipping Conflict of interest as it is not in the selected sections.\n",
      "Skipping Generative AI statement as it is not in the selected sections.\n",
      "Skipping Publisher's note as it is not in the selected sections.\n",
      "Skipping References as it is not in the selected sections.\n",
      "Selected: Introduction, Experiments, Discussion, Conclusion\n",
      "Skipping Related work as it is not in the selected sections.\n",
      "Skipping Method as it is not in the selected sections.\n",
      "Skipping Experiments as it is not in the selected sections.\n",
      "Skipping Discussion as it is not in the selected sections.\n",
      "Skipping Conclusion as it is not in the selected sections.\n",
      "Skipping Data availability statement as it is not in the selected sections.\n",
      "Skipping Author contributions as it is not in the selected sections.\n",
      "Skipping Funding as it is not in the selected sections.\n",
      "Skipping Conflict of interest as it is not in the selected sections.\n",
      "Skipping Generative AI statement as it is not in the selected sections.\n",
      "Skipping Publisher's note as it is not in the selected sections.\n",
      "Skipping References as it is not in the selected sections.\n"
     ]
    }
   ],
   "source": [
    "text_to_read = selective_reading(file, call_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d5f66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "reader_prompt = f\"Read the following paper and {text_to_read}.\\n\\n\"\n",
    "reader_prompt += f\"Give intermediate thinking of the question including reasoning and useful details: {query}\\n\\n\"\n",
    "\n",
    "intermediate_answer = call_llm(system_prompt, reader_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72dabb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me break down the main findings of this paper through careful analysis:\n",
      "\n",
      "Key Components:\n",
      "1. Novel Approach:\n",
      "- Developed \"SympCoughNet\" - a deep learning model that combines both cough audio data and clinical symptom information\n",
      "- Previous approaches mostly focused only on audio classification\n",
      "\n",
      "2. Performance Metrics:\n",
      "- Achieved significant results:\n",
      "  * 89.30% accuracy\n",
      "  * 94.74% AUROC\n",
      "  * 91.62% PR on test set\n",
      "- These results showed improvement over traditional audio-only approaches\n",
      "\n",
      "3. Dataset:\n",
      "- Used UK COVID-19 Vocal Audio Dataset\n",
      "- Large scale: 72,999 participants\n",
      "- Included 25,766 positive PCR cases\n",
      "- Contains coughs, sequential coughs, breathing sounds, and self-reported symptoms\n",
      "\n",
      "4. Innovation:\n",
      "- Integrated symptom data as prior knowledge through symptom-encoded channel weighting\n",
      "- Successfully demonstrated that incorporating symptom data enhances COVID-19 detection\n",
      "- Found that even incorrect symptom inputs could influence predictions\n",
      "\n",
      "Main Finding:\n",
      "The primary finding is that combining clinical symptom data with cough audio analysis significantly improves COVID-19 detection accuracy compared to traditional audio-only approaches. This was achieved through their novel SympCoughNet architecture that uses symptom-encoded channel weighting to enhance feature processing.\n",
      "\n",
      "This finding is significant because it offers a more comprehensive and accurate approach to COVID-19 detection while maintaining the advantages of being non-invasive and easily accessible.\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def intermediate_reading(llm_func):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    text_to_read = selective_reading(file, llm_func)\n",
    "    \n",
    "    reader_prompt = f\"Read the following paper and {text_to_read}.\\n\\n\"\n",
    "    reader_prompt += f\"Give intermediate thinking of the question including reasoning and useful details: {query}\\n\\n\"\n",
    "\n",
    "    intermediate_answer = call_llm(system_prompt, reader_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
